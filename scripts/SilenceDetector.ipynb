{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m pip install PyMySQL\n",
    "!python3 -m pip install SQLAlchemy\n",
    "!python3 -m pip install google-cloud-storage\n",
    "!python3 -m pip install --upgrade --quiet scikit-sound\n",
    "!python3 -m pip install --upgrade --quiet pygame\n",
    "!sudo apt-get -y install ffmpeg\n",
    "!sudo apt-get -y install python3-pymysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 1.9.6\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import sqlalchemy\n",
    "import numpy as np\n",
    "\n",
    "from google.cloud import storage\n",
    "from numpy.fft import fft, ifft\n",
    "from sksound.sounds import Sound\n",
    "from scipy.io import wavfile\n",
    "\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "highpass=25\n",
    "\n",
    "class StreamSpectrogram:\n",
    "    \n",
    "    def __init__(self, filename, win=128):\n",
    "        sound = Sound(filename)        \n",
    "        self.batch = sound.rate * 60\n",
    "        self.data  = sound.data\n",
    "        self.fs    = sound.rate\n",
    "        if len(self.data.shape) > 1:\n",
    "            self.data = self.data[:, 0]    \n",
    "        self.win = win\n",
    "        \n",
    "    def __iter__(self):\n",
    "        self.i = 0\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        if (self.i + 1) * self.batch < len(self.data): \n",
    "            start = self.i       * self.batch\n",
    "            stop  = (self.i + 1) * self.batch\n",
    "            raw   = self.data[start:stop]\n",
    "            spec  = fwd_spectrogram(raw, win=512 + 2 * highpass)[:, 0:256] \n",
    "            t,d   = spec.shape\n",
    "            current = []        \n",
    "            for i in range(self.win, t, self.win // 2):\n",
    "                x      = np.reshape(spec[i - self.win:i], (self.win, d, 1))\n",
    "                mu     = np.mean(x)\n",
    "                std    = np.std(x) + 1.0\n",
    "                window = (x - mu) / std\n",
    "                current.append(window)\n",
    "            self.i += 1\n",
    "            return np.stack(current)\n",
    "        else:\n",
    "            raise StopIteration\n",
    "     \n",
    "    def snippet(self, start, stop):\n",
    "        w = 512 + 2 * highpass\n",
    "        if start - w > 0:\n",
    "            return self.data[start - w:stop]\n",
    "        else:\n",
    "            return None\n",
    "    \n",
    "def fwd_spectrogram(audio, win=512, step=64):\n",
    "    '''\n",
    "    Compute the spectrogram of audio data\n",
    "\n",
    "    audio: one channel audio\n",
    "    win: window size for dft sliding window\n",
    "    step: step size for dft sliding windo\n",
    "    '''\n",
    "    spectrogram = []\n",
    "    hanning = np.hanning(win)\n",
    "    for i in range(win, len(audio), step):\n",
    "        start = win // 2\n",
    "        dft = np.abs(fft(audio[i - win: i] * hanning))[start:win]\n",
    "        spectrogram.append(dft)\n",
    "    return np.array(spectrogram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PASSWORDS AND STUFF HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = {\n",
    "   'user': db_user,\n",
    "   'pass': db_password,\n",
    "   'host': host,\n",
    "     'db': db_name\n",
    "}\n",
    "url = 'mysql+pymysql://{user}:{pass}@{host}/{db}'.format(**settings)  # 5432 is the default port\n",
    "db = sqlalchemy.create_engine(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_query(query):\n",
    "    with db.connect() as conn:\n",
    "        rows = []\n",
    "        for row in conn.execute(query).fetchall():\n",
    "            rows.append(dict(row.items()))\n",
    "        return rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = run_query(\"\"\"\n",
    "    SELECT \n",
    "        x.encoding, y.year, x.filename \n",
    "    FROM \n",
    "        wdp_ds.audio x \n",
    "    JOIN wdp_ds.encoding y ON x.encoding = y.encoding;\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = [\"audio_files/{}/{}\".format(file['year'], file['filename']) for file in files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "max_id = run_query(\"\"\"\n",
    "    SELECT \n",
    "        max(id)\n",
    "    FROM \n",
    "        wdp_ds.not_silent\n",
    "    \"\"\")\n",
    "if max_id[0]['max(id)'] is None:\n",
    "    max_id = 0\n",
    "else:\n",
    "    max_id = max_id[0]['max(id)']\n",
    "print(max_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../ml\") \n",
    "\n",
    "models = '../models/lstm_v4/v4.2/'\n",
    "\n",
    "from train_silence_detector import detector\n",
    "from train_lstm_auto_encoder_variational import VAE\n",
    "\n",
    "vae = VAE()\n",
    "vae.auto_encoder((128, 256, 1), 128, 256 * 128, 128)\n",
    "encoder = vae.encoder \n",
    "noise_classifier = detector(128, encoder)\n",
    "encoder.load_weights('{}encoder.h5'.format(models))\n",
    "noise_classifier.load_weights('{}sil.h5'.format(models))\n",
    "encoder.summary()\n",
    "\n",
    "\n",
    "#noise_classifier = load_model('../models/lstm_v4/v4.2/sil.h5')\n",
    "client = storage.Client.from_service_account_json('../secret.json')\n",
    "bucket = client.get_bucket('wdp-data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id = max_id + 1\n",
    "skip = 0\n",
    "c = 0\n",
    "for path, file_dict in zip(paths, files):\n",
    "    if c > skip:\n",
    "        print(path, file_dict, c)\n",
    "        with open(\"/tmp/audio.m4a\", \"wb\") as file_obj:\n",
    "            blob = bucket.blob(path)\n",
    "            blob.download_to_file(file_obj)\n",
    "        stream = StreamSpectrogram(\"/tmp/audio.m4a\")\n",
    "        not_noise = []\n",
    "        for x in stream:\n",
    "            y = noise_classifier.predict(x).flatten()\n",
    "            not_noise.extend([int(np.round(sample)) == 0 for sample in y])\n",
    "\n",
    "        regions = []\n",
    "        for i in range(0, len(not_noise)):\n",
    "            if not_noise[i]:\n",
    "                #win: 32, step: 256\n",
    "                #start = i * 16 * 256\n",
    "                #stop  = (i + 1) * 16 * 256 \n",
    "                # win: 128, step: 64\n",
    "                start = i * 64 * 64\n",
    "                stop  = (i + 1) * 64 * 64 \n",
    "\n",
    "                if len(regions) > 0: \n",
    "                    last  = regions[-1]\n",
    "                    if start - last[1] < 48000 * 0.1:\n",
    "                        start       = regions[-1][0]\n",
    "                        regions[-1] = (start, stop)\n",
    "                    else:\n",
    "                        regions.append((start, stop))\n",
    "                else:\n",
    "                    regions.append((start, stop))\n",
    "        regions = [(start, stop) for start, stop in regions if stop - start > (64 * 64)]\n",
    "        if len(regions) > 0:\n",
    "            #for start, stop in regions:\n",
    "            #    audio = stream.snippet(start, stop)\n",
    "            #   if audio is not None:\n",
    "            #       wavfile.write('../data/silence/{}_{}_{}.wav'.format(file_dict['encoding'], start,stop), stream.fs, audio)\n",
    "\n",
    "            with db.connect() as conn:\n",
    "                for start, stop in regions:                \n",
    "                    conn.execute(\"INSERT INTO wdp_ds.not_silent VALUES ({}, {}, '{}', {}, {})\".format(id, file_dict['encoding'], file_dict['filename'], start, stop))  \n",
    "                    id += 1\n",
    "        print(file_dict['encoding'], \": \", regions)\n",
    "    c += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
